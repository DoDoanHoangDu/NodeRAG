{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61b59749",
   "metadata": {},
   "source": [
    "# Notebook 2: Important Nodes Detection\n",
    "\n",
    "This notebook processes the primary graph **G1** to detect structurally important nodes using **K-core importance** and **Betweenness Centrality**.  \n",
    "\n",
    "The results are saved for future augmentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4663bcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory of this script is: c:\\Users\\HP\\Desktop\\Projects\\NodeRAG\\graphs\n",
      "The root directory is: c:\\Users\\HP\\Desktop\\Projects\\NodeRAG\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dir_path = os.getcwd()\n",
    "print(\"The directory of this script is:\", dir_path)\n",
    "root_path = os.path.dirname(dir_path)\n",
    "print(\"The root directory is:\", root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44c6fa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Node class definition\n",
    "import sys\n",
    "sys.path.append(root_path)\n",
    "from graphs.Node import Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4165f4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load primary graph G1 with S,N,R nodes\n",
    "import pickle\n",
    "with open(f\"{root_path}/graphs/data/graphs/G1_medical_primary_graph.pkl\", \"rb\") as f:\n",
    "    medical_nodes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d5f9a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "589"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find k-core important nodes: entity nodes with number of connection >= k_default\n",
    "import math\n",
    "def k_default(nodes):\n",
    "    V = len(nodes)\n",
    "    sum_deg = sum([node.degree for node in nodes.values()])\n",
    "    k_avg = sum_deg / V\n",
    "    k_def = math.floor(math.log(V) * math.sqrt(k_avg))\n",
    "    return k_def\n",
    "\n",
    "def k_core_importance(nodes):\n",
    "    k = k_default(nodes)\n",
    "    important_nodes = {node_id: node for node_id, node in nodes.items() if node.degree >= k and node.node_type == \"N\"}\n",
    "    return important_nodes\n",
    "\n",
    "k_core_nodes_medical = k_core_importance(medical_nodes)\n",
    "len(k_core_nodes_medical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82b1632d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3144/3144 [11:19<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of important medical nodes: 555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import heapq\n",
    "from tqdm import tqdm\n",
    "\n",
    "def approximate_betweenness_weighted(nodes_dict, k_sample=10):\n",
    "    #Betweenness centrality measures how frequently a node appears on the shortest path between a pair of nodes in the graph.\n",
    "    #Brandes' algorithm with sampling (approximate using k nodes instead of all nodes)\n",
    "    node_ids = list(nodes_dict.keys())\n",
    "    sampled_nodes = random.sample(node_ids, min(k_sample, len(node_ids)))  # pick k nodes randomly\n",
    "    bc = {node_id: 0.0 for node_id in node_ids}  #initialize\n",
    "    \n",
    "    for i in tqdm(range(k_sample)):\n",
    "        s_id = sampled_nodes[i]\n",
    "        #Dijkstra shortest paths from s_id\n",
    "        dist = {nid: float('inf') for nid in node_ids}\n",
    "        num_paths = {nid: 0 for nid in node_ids}\n",
    "        pred = {nid: [] for nid in node_ids}\n",
    "        #init\n",
    "        dist[s_id] = 0\n",
    "        num_paths[s_id] = 1\n",
    "        heap = [(0, s_id)]\n",
    "        \n",
    "        while heap:\n",
    "            d_u, u = heapq.heappop(heap)\n",
    "            if d_u > dist[u]:\n",
    "                continue\n",
    "            \n",
    "            for v, w in nodes_dict[u].edges.items():\n",
    "                alt = dist[u] + w\n",
    "                if alt < dist[v]:\n",
    "                    dist[v] = alt\n",
    "                    heapq.heappush(heap, (alt, v))\n",
    "                    num_paths[v] = num_paths[u]\n",
    "                    pred[v] = [u]\n",
    "                elif alt == dist[v]:\n",
    "                    num_paths[v] += num_paths[u]\n",
    "                    pred[v].append(u)\n",
    "        \n",
    "        #backpropagation: accumulate dependencies - how much each node lies on top of the shortest path between the source node and other nodes\n",
    "        delta = {nid: 0 for nid in node_ids} #dependency scores\n",
    "        nodes_by_dist = sorted(dist.items(), key=lambda x: -x[1]) #decreasing order of distance: dependency propagates from the leaf nodes up to the source\n",
    "        for v, _ in nodes_by_dist:\n",
    "            for u in pred[v]:\n",
    "                # fraction of shortest paths through u\n",
    "                if num_paths[v] > 0:\n",
    "                    delta[u] += (num_paths[u] / num_paths[v]) * (1 + delta[v])\n",
    "            if v != s_id:\n",
    "                bc[v] += delta[v]\n",
    "    \n",
    "    #threshold\n",
    "    for v in bc:\n",
    "        bc[v] /= k_sample\n",
    "    avg_bc = sum(bc.values()) / len(bc)\n",
    "    scale = int(math.log10(len(nodes_dict)))\n",
    "    important_nodes = {v: nodes_dict[v] for v, score in bc.items() if score > avg_bc * scale and nodes_dict[v].node_type == \"N\"}\n",
    "    \n",
    "    return important_nodes\n",
    "\n",
    "bc_medical_nodes = approximate_betweenness_weighted(medical_nodes, k_sample=len(medical_nodes)//10)\n",
    "\n",
    "print(\"Number of important medical nodes:\", len(bc_medical_nodes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39250aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#sanity check\n",
    "def shared_keys_different_values(dict1, dict2):\n",
    "    for key in dict1:\n",
    "        if key in dict2 and dict1[key] != dict2[key]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "print(shared_keys_different_values(k_core_nodes_medical, bc_medical_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e54b2e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total important medical nodes: 686\n"
     ]
    }
   ],
   "source": [
    "#union of 2 types of important nodes\n",
    "important_medical_nodes = {**k_core_nodes_medical, **bc_medical_nodes}\n",
    "print(\"Total important medical nodes:\", len(important_medical_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9331f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/nodes/attribute/important_medical_nodes.json\", \"w\") as f:\n",
    "    json.dump(list(important_medical_nodes.keys()), f, indent=2)\n",
    "with open(\"data/nodes/attribute/important_medical_nodes.json\", \"r\") as f:\n",
    "    important_medical_nodes_loaded = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc6d36e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#sanity check\n",
    "for id in important_medical_nodes_loaded:\n",
    "    if id not in medical_nodes:\n",
    "        print(\"Invalid Medical ID:\", id)\n",
    "print(\"-\"*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
